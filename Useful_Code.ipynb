{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTS\n",
    "\"\"\"\n",
    "\n",
    "from hummingbirdtech.analysis.core import image\n",
    "from hummingbirdtech.dic.container import Container\n",
    "from hummingbirdtech.domain.sensor import Band\n",
    "from hummingbirdtech.analysis.core import image_clipper\n",
    "\n",
    "logger = Container().get('logger')\n",
    "\n",
    "ndre_service = Container().get('hummingbird.vegetation_indices.ndre')\n",
    "ndvi_service = Container().get('hummingbird.vegetation_indices.ndvi')\n",
    "\n",
    "# add parameter to container (could also be int or float)\n",
    "Container().add_parameter(\"assigned_name\", np.array([77,88.9,99.99,88.765]))\n",
    "\n",
    "# retrieve parameter form container\n",
    "Container().get_parameter(\"assigned_name\")\n",
    "\n",
    "# find container services\n",
    "container.debug('clipper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# Clip image with a polygon (either geographic or projected coordinates) (specific polygon e.g. polygon_mask.ix[0].geometry)\n",
    "polygon_mask = gpd.read_file(\"polygon_filename\")\n",
    "polygon_clip = image_clipper_service.clip_image_with_geographic_polygon(image=image_orig, polygon=specific_polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history search\n",
    "ctrl+r\n",
    "\n",
    "# recursively delete files/folder (HARD)\n",
    "$ rm -rf\n",
    "\n",
    "# list jupyter themes\n",
    "$ jt -l\n",
    "\n",
    "# change jupyter themes\n",
    "$ jt -t some_theme\n",
    "\n",
    "# reset jupyter theme to default\n",
    "$ jt -r\n",
    "\n",
    "# initiate bash window\n",
    "$ bash\n",
    "\n",
    "# write the user name (i.e., login name) of the owner of the current login session to standard output\n",
    "$ whoami\n",
    "\n",
    "# end terminal sessions and close window (bash_profile alias)\n",
    "$ exit\n",
    "$ ee\n",
    "\n",
    "# start ssh agent\n",
    "$ (ssh-agent)\n",
    "\n",
    "# add private key to ssh agent\n",
    "$ ssh-add\n",
    "\n",
    "# permanently save ssh key\n",
    "$ ssh-add -K\n",
    "\n",
    "# pull updates to a git repo from the origin (GitHub) to the develop branch (local) (bash_profile alias)\n",
    "$ git pull origin develop\n",
    "$ gp\n",
    "\n",
    "# delete a local branch\n",
    "$ git branch -d branch_name\n",
    "\n",
    "# list git branches\n",
    "$ git branch -a\n",
    "\n",
    "# create new branch and switch to it\n",
    "$ git checkout -b new_branch_name\n",
    "\n",
    "# read file contains in bash / terminal window\n",
    "$ cat some_file\n",
    "\n",
    "# close terminal\n",
    "$ exit\n",
    "\n",
    "# count number of files in a folder (bash_profile alias)\n",
    "$ ls | wc -l\n",
    "$ ll\n",
    "\n",
    "# create new empty file\n",
    "$ touch name_of_some_file.txt\n",
    "\n",
    "# launch jupyter notebook (bash_profile alias)\n",
    "$ jupyter notebook\n",
    "$ jn\n",
    "\n",
    "# launch python (bash_profile alias)\n",
    "$ python\n",
    "$ py\n",
    "\n",
    "# launch ipython (bash_profile alias)\n",
    "$ ipython\n",
    "$ ipy\n",
    "\n",
    "# launch bash_profile in vi (bash_profile alias)\n",
    "$ vi ~/.bash_profile\n",
    "$ bp\n",
    "\n",
    "# restart bash_profile (bash_profile alias)\n",
    "$ source ~/.bash_profile\n",
    "$ re_bp\n",
    "\n",
    "# reset terminal completely\n",
    "$ reset\n",
    "\n",
    "# sync all changes with a source fodler within a target_folder (bin folder for additional scripts)\n",
    "$ rsync -avh source_folder target_folder --delete\n",
    "$ rsync-folders source_folder target_folder\n",
    "\n",
    "# convert iPython notebook to executable python file (bin folder for additional scripts)\n",
    "$ ipython nbconvert --to python ipython_notebook.ipynb\n",
    "$ nb-to-py some_notebook.ipynb\n",
    "\n",
    "# SSH into VM (bin folder for additional scripts)\n",
    "$ gcloud compute --project \"hummingbird-technologies\" ssh --zone \"europe-west1-b\" \"hb-adhoc-orthomosaic\"\n",
    "$ go-adhoc-ortho\n",
    "\n",
    "# forward jupyterhub port to local browser (bin folder for additional scripts)\n",
    "$ gcloud compute --project \"hummingbird-technologies\" ssh --zone \"europe-west1-b\" \"hb-jupyter-hub\" -- -N -f -L 8000:localhost:8000\n",
    "$ forward-jupyterhub-port\n",
    "\n",
    "# ssh into jupyterhub\n",
    "$ gcloud compute --project \"hummingbird-technologies\" ssh --zone \"europe-west1-b\" \"hb-jupyter-hub\"\n",
    "$ jhub-ssh\n",
    "\n",
    "# display image meta data (bin folder for additional scripts)\n",
    "$ exiftool -a -G1 -s some_image.tif\n",
    "$ get-image-meta some_image.tif\n",
    "\n",
    "# download reflectance image from cloud (bin folder for additional scripts)\n",
    "$ gsutil -m cp gs://hummingbirdtech-production-processed/$ID-reflectance.tif .\n",
    "$ get-field-tiff field_survey_number save_folder\n",
    "\n",
    "# transfer data from local directory to VM Jupyter server  (bin folder for additional scripts)\n",
    "$ gsutil -m cp -r ./some_local_file gs://hb-data/home/alex/\n",
    "$ data-to-cloud some_file\n",
    "\n",
    "# transfer data from Jupyter Hub remote server to local (bin folder for additional scripts)\n",
    "$ gsutil -m cp -r gs://hb-data/home/alex/$ID .\n",
    "$ data-from-cloud\n",
    "\n",
    "# change permission of a file / folder (bin folder for additional scripts)\n",
    "$ chmod 755 folder_or_file\n",
    "$ chmod 755 $ID\n",
    "\n",
    "    # chmod codes\n",
    "    0 = --- = no access\n",
    "    1 = --x = execute\n",
    "    2 = -w- = write\n",
    "    3 = -wx = write / execute\n",
    "    4 = r-- = read\n",
    "    5 = r-x = read / execute\n",
    "    6 = rw- = read / write\n",
    "    7 = rwx = read / write / execute\n",
    "\n",
    "# super user do (provide / override neccessary permissions for a task)\n",
    "$ sudo another_command\n",
    "\n",
    "# create a new python environment\n",
    "$ conda create -n myenv python=3.4\n",
    "\n",
    "# activate python environment\n",
    "$ source activate py35\n",
    "\n",
    "# deactivate python environment\n",
    "$ source deactivate py35\n",
    "\n",
    "# monitor current processes (to monitor processes for a specific user, u -> username)\n",
    "$ top\n",
    "\n",
    "# find where an applicatoin is store\n",
    "$ which python\n",
    "\n",
    "# unzip file to specific destination\n",
    "$ unzip file.zip -d destination_folder\n",
    "\n",
    "# delete branch locally\n",
    "$ git branch -d branch_name\n",
    "\n",
    "# delete branch from remote repo\n",
    "$ git push your_remote :branch_name\n",
    "    \n",
    "# stash/save/store changes form one branhc\n",
    "$ git stash\n",
    "\n",
    "# list stashed changes\n",
    "$ git stash list\n",
    "\n",
    "# aplly stashed changes to current branch\n",
    "$ git stash apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### General Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set wide width to notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# turns off scientific notation (e.g. 1.52329e+3 is now 1523.29) and sets decimal precision to 2\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# check if a filepath exists - returns True if so and False if it does not exist\n",
    "import os.path\n",
    "os.path.isfile(filepath) \n",
    "\n",
    "# get current working directory\n",
    "wd = os.getcwd()\n",
    "\n",
    "# add a progress bar to a loop\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000)):\n",
    "\n",
    "# extract True values within masked array (output is 1D array)\n",
    "values = ma.compressed(array)\n",
    "\n",
    "# Apply gaussian blur filter with specified sigma value\n",
    "from skimage import filters\n",
    "subset_gblur = filters.gaussian(subset, sigma=3)\n",
    "\n",
    "# masked array\n",
    "ma.array(array, mask)\n",
    "\n",
    "# call command line function in python script (not using magic keys)\n",
    "subprocess.call([\"ls\", \"-l\"])\n",
    "subprocess.check_output([\"ls\", \"-l\"])\n",
    "\n",
    "# unique values in an array\n",
    "np.unique(array)\n",
    "\n",
    "# find where a condition in a array is met and optionally replace the values where that condition is true with avalue and where it is false with another value\n",
    "np.where(condition, x, y)\n",
    "\n",
    "# changing value\n",
    "\"{}\".format()\n",
    "\n",
    "# strip character off the end of a string\n",
    "string.rstrip([characters])\n",
    "\n",
    "# set up plot for multiple image in one figure\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(10,5), sharex=True, sharey=True)\n",
    "\n",
    "# loop though bands\n",
    "for band_number, band_name in enumerate([\"blue\", \"green\", \"red\", \"nir\", \"rededge\"]):\n",
    "\n",
    "# save figure\n",
    "plt.savefig(\"save_path.png\")\n",
    "\n",
    "# plot colorbar\n",
    "fig.colorbar(cax, ax)\n",
    "\n",
    "# set x, y tick labels (none in this case)\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_yticklabels([])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# set line in histogram\n",
    "ax[0].axvline(value_at_line, color='r', linestyle='dashed', linewidth=2, alpha=1)\n",
    "\n",
    "# set transparency of histogram\n",
    "plt.hist(image_array.ravel(), alpha=0.5)\n",
    "\n",
    "# set bins of histogram\n",
    "plt.hist(image_array.ravel(), 50)\n",
    "\n",
    "# create a pandas dataframe\n",
    "df = pd.DataFrame({\"col1\":[value], \"col2\":[value], \"col3\":[value]})\n",
    "\n",
    "# add a column to pandas dataframe\n",
    "df_new = df.assign(new_col=[])\n",
    "\n",
    "# iterarate through index and rows in a pandas dataframe\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "# concatenate pandas dataframe\n",
    "concatenated_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# concatenate multiple arrays / lists\n",
    "concatenated_array = np.concatenate((item_1, item_2), axis=0)\n",
    "\n",
    "# reindex pandas dataframe\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# delete a row (or mulitple rows) of a pandas dataframe\n",
    "df = df.drop(df.index[9])\n",
    "\n",
    "# show head of dataframe\n",
    "df.head()\n",
    "\n",
    "# read dataframe from a pickle file\n",
    "df = pd.read_pickle(\"file_pathname.pkl\")\n",
    "\n",
    "# sort values by column\n",
    "df = df.sort_values(by=['col1'])\n",
    "\n",
    "# read dataframe from a csv file\n",
    "df = pd.read_csv(\"file_pathname.csv\")\n",
    "\n",
    "# save dataframe as pickle file\n",
    "df.to_pickle(\"file_pathname.pkl\")\n",
    "\n",
    "# standardize an image (takes 2D array and not suitable for masked array)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized_data = StandardScaler().fit_transform(image_array)\n",
    "\n",
    "# rescale an image (takes 2D array and not suitable for masked array)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "rescaled_data = MinMaxScaler().fit_transform(image_array)\n",
    "\n",
    "# save an image - bear in mind that to save a 3D array you have to reshape it\n",
    "from scipy.misc import imsave\n",
    "imsave(\"save_pathname.png\", image_array)\n",
    "\n",
    "# reshape / transpose a 3D array\n",
    "reshaped_array = np.ascontiguousarray(image_array.transpose(1,2,0))\n",
    "\n",
    "# transpose an array\n",
    "transposed_array = image_array.T\n",
    "\n",
    "# one line loop - some action / statement for that in an iterable object\n",
    "output = [x+1 for x in range(1,11)]\n",
    "output = [x for x in range(4)]\n",
    "\n",
    "# one line function (example is with two arguments and returns a tuple, although both of these are flexible)\n",
    "function = lambda x,y: (x+2, y-6)\n",
    "function(suitable_input)\n",
    "\n",
    "# downsample an image (example given is 3D array)\n",
    "from skimage.measure import block_reduce\n",
    "block_reduce(image_array, (1,100,100))\n",
    "\n",
    "# set plot parameters\n",
    "FONTSIZE = 45\n",
    "TICKS_FONTSIZE = 20\n",
    "TITLE_FONTSIZE = 20\n",
    "FIGURE_SIZE = (10,8)\n",
    "params = {'legend.fontsize': FONTSIZE,\n",
    "          'figure.figsize': FIGURE_SIZE,\n",
    "         'axes.labelsize': FONTSIZE,\n",
    "         'axes.titlesize': TITLE_FONTSIZE,\n",
    "         'xtick.labelsize': TICKS_FONTSIZE,\n",
    "         'ytick.labelsize': TICKS_FONTSIZE}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# set parameters / license to use google cloud\n",
    "import os\n",
    "os.environ['MACHINE_ENVIRONMENT']='dev'\n",
    "os.environ['GCLOUD_IMAGES_BUCKET_DIR'] = 'test'\n",
    "os.environ['API_HOST_NAME'] = 'https://api.hummingbirdtech.com'\n",
    "os.environ['API_PRIVATE_KEY_PATH'] = '/Users/AlexKemp/Hummingbird/licenses/staging_private_key.pem'\n",
    "os.environ['API_USER_NAME'] = \"admin@hummingbirdtech.com\"\n",
    "os.environ['API_PRIVATE_KEY_PASSWORD'] = 'hummingbird'\n",
    "os.environ['API_TIMEOUT'] = '30'\n",
    "os.environ['GCLOUD_IMAGES_BUCKET_NAME'] = 'hummingbirdtech-production-processed'\n",
    "os.environ['GCLOUD_PROJECT'] = 'hummingbird-technologies'\n",
    "os.environ['GCLOUD_INGESTION_HOST'] = '123'\n",
    "os.environ['GCLOUD_CREDENTIALS_PATH'] = '/Users/AlexKemp/Hummingbird/licenses/Hummingbird-Technologies-2f7bad82395b.json'\n",
    "os.environ['DIRECTOR_INGESTION_HOST'] = 'http://ingestion.hummingbirdtech.com'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/AlexKemp/Hummingbird/licenses/Hummingbird-Technologies-2f7bad82395b.json'\n",
    "os.environ['FS_LOCAL_ROOT'] = '/Users/AlexKemp/'\n",
    "os.environ['HB_GOOGLE_STORAGE_LOCAL_PATH'] = \"/Users/AlexKemp/Hummingbird/hummingbird_local_storage/hummingbird-cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert collection of VRA boundaries (VariableRateApplicationBoundaryCollection) to shapefile\n",
    "def lazy_vra_collection_to_shapefile(vra_boundary_collection, output_shapefile_name):\n",
    "    import geopandas as gpd\n",
    "    \n",
    "    poly_list = []\n",
    "    for b in vra_boundary_collection.variable_rate_application_boundaries:\n",
    "        poly_list.append([b.boundary, b.value])\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(poly_list, columns=[\"geometry\", \"val\"])\n",
    "    gdf.val = gdf.val.apply(lambda x: float(x))\n",
    "    gdf.crs = {\"init\": 'epsg:4326'}\n",
    "    gdf.to_file(output_shapefile_name, driver=\"ESRI Shapefile\")\n",
    "    print(\"Saved collection to {}\".format(output_shapefile_name))\n",
    "\n",
    "# grow square region from the centre of an image\n",
    "def grow_from_centre(image_array, pixel_distance):\n",
    "    \n",
    "    mid_row = int(image_array.shape[0] / 2)\n",
    "    mid_col = int(image_array.shape[1] / 2)\n",
    "    \n",
    "    uly = (mid_row-pixel_distance)\n",
    "    lry = (mid_row+pixel_distance)\n",
    "    ulx = (mid_col-pixel_distance)\n",
    "    lrx = (mid_col+pixel_distance)\n",
    "    \n",
    "    return image_array[uly:lry, ulx:lrx]\n",
    "\n",
    "# mask out 0 values\n",
    "import numpy.ma as ma\n",
    "def mask_out_zeros(image_array):\n",
    "    mask = image_array <= 0\n",
    "    return ma.array(image_array, mask=mask)\n",
    "\n",
    "# run KMeans (using Spectral Python)\n",
    "from spectral import *\n",
    "def run_kmeans(image_array, clusters, iterations):\n",
    "    \"\"\"\n",
    "    Function which runs the KMeans clustering algorithm on an image and\n",
    "    returns the classified image and the cluster centres\n",
    "    \"\"\"\n",
    "    # traspose image so that the array is in correct structure\n",
    "    image_array_transpose = image_array.T\n",
    "    # apply KMeans unsupervised classification\n",
    "    m, c = kmeans(image_array_transpose, clusters, iterations)\n",
    "    return (m.T, c)\n",
    "\n",
    "# get binary cluster images from KMeans result\n",
    "def get_binary_cluster_array(m, cluster_number):\n",
    "    return np.where(m==cluster_number, 1, 0)\n",
    "\n",
    "# get masked array from KMeans result\n",
    "def get_masked_array(m, image_array, band_number, cluster_number):\n",
    "    \"\"\"\n",
    "    Function which takes a classified kmeans image and applies a mask\n",
    "    to the original image using one of the clusters\n",
    "    \"\"\"\n",
    "    mask = np.where(m==cluster_number, False, True)\n",
    "    return ma.array(image_array[band_number], mask=mask)\n",
    "\n",
    "# get mean, min, max and std values of a masked array\n",
    "def get_masked_array_values(masked_array): \n",
    "    mean = np.nanmean(masked_array)\n",
    "    minim = np.nanmin(masked_array)\n",
    "    maxim = np.nanmax(masked_array)\n",
    "    std = np.nanstd(masked_array)\n",
    "    return mean, minim, maxim, std\n",
    "\n",
    "# open polygon dataframe\n",
    "def open_polygon_dataframe(polygon_filename):\n",
    "    return gpd.read_file(polygon_filename)\n",
    "\n",
    "# clip image array with polygon (polygon geometry specified in dataframe)\n",
    "def clip_image_with_polygon(image_original, polygon_dataframe, polygon_number):\n",
    "    clipped_image = image_clipper_service.clip_image_with_geographic_polygon(image=image_original,\\\n",
    "                                                                             polygon=polygon_dataframe.\\\n",
    "                                                                             loc[polygon_number].geometry)\n",
    "    return clipped_image.to_ndarray()\n",
    "\n",
    "# normalize an image/array (suitable for masked array):\n",
    "def normalize_array(image_array, band_number):\n",
    "    image_min = np.nanmin(image_array[band_number])\n",
    "    image_max = np.nanmax(image_array[band_number])\n",
    "    return (image_array[band_number]-image_min) / (image_max-image_min)\n",
    "\n",
    "# standardize an image (suitable for masked array)\n",
    "def standarize_image(image_array, band_number):\n",
    "    image_mean = np.nanmean(image_array[band_number])\n",
    "    image_std = np.nanstd(image_array[band_number])\n",
    "    return (image_array[band_number]-image_mean) / image_std\n",
    "\n",
    "# plot an image\n",
    "def plot_image(image, title, size):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show\n",
    "    \n",
    "# plot a histogram of a masked image\n",
    "def plot_histo(image, bins, size, xlabel, ylabel):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.hist(ma.compressed(image), bins)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "# plot every band, ndvi and ndre of a single stacked image array\n",
    "def plot_image(image_array, ndvi, ndre):\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(25,10), sharex=True, sharey=False)\n",
    "\n",
    "    cax1 = ax[0,0].imshow(image_array[0])\n",
    "    ax[0,0].set_title(\"Green\")\n",
    "    ax[0,0].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax1, ax=ax[0,0])\n",
    "\n",
    "    cax2 = ax[0,1].imshow(image_array[1])\n",
    "    ax[0,1].set_title(\"Red\")\n",
    "    ax[0,1].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax2, ax=ax[0,1])\n",
    "\n",
    "    cax3 = ax[0,2].imshow(image_array[2])\n",
    "    ax[0,2].set_title(\"Rededge\")\n",
    "    ax[0,2].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax3, ax=ax[0,2])\n",
    "\n",
    "    cax4 = ax[1,0].imshow(image_array[3])\n",
    "    ax[1,0].set_title(\"NIR\")\n",
    "    ax[1,0].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax4, ax=ax[1,0])\n",
    "\n",
    "    cax5 = ax[1,1].imshow(ndvi)\n",
    "    ax[1,1].set_title(\"NDVI\")\n",
    "    ax[1,1].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax5, ax=ax[1,1])\n",
    "\n",
    "    cax6 = ax[1,2].imshow(ndre)\n",
    "    ax[1,2].set_title(\"NDRE\")\n",
    "    ax[1,2].set_adjustable(\"box-forced\")\n",
    "    fig.colorbar(cax6, ax=ax[1,2])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# get soil pixels using tramline detector and matched filter\n",
    "def get_soil(image, percentile=90):\n",
    "    \n",
    "    tramlines = tramline_detector.get_tramline_image(image)\n",
    "    tramline_locations = np.where(tramlines == 1)\n",
    "    \n",
    "    image_pixels = image.to_ndarray()[0:4]\n",
    "    image_pixels[image_pixels == -10000] = np.nan\n",
    "    \n",
    "    tramline_pixels = image_pixels[:, tramline_locations[0], tramline_locations[1]]\n",
    "    target_spectra = np.nanmean(tramline_pixels, axis=1)\n",
    "    \n",
    "    image_pixels[np.isnan(image_pixels)] = 0\n",
    "    soil_pixels = spectral.matched_filter(image_pixels.transpose(1, 2, 0), target_spectra)\n",
    "    \n",
    "    threshold = np.nanpercentile(soil_pixels, percentile)\n",
    "    \n",
    "    return soil_pixels > threshold\n",
    "\n",
    "# function to write the an array out as a raster GeoTIFF with the same geolocation metadata as the target image\n",
    "def array_to_raster(save_array, target_image, save_pathname):\n",
    "    # Define geolocation information\n",
    "    width = target_image.RasterXSize\n",
    "    height = target_image.RasterYSize\n",
    "    geoTransform = target_image.GetGeoTransform()\n",
    "    projection = target_image.GetProjection() \n",
    "    # Create GeoTIFF dataset, according to geolocation information, and write it to a raster file\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = driver.Create(save_pathname, width, height, 1, gdal.GDT_Float32)\n",
    "    dataset.SetGeoTransform(geoTransform)\n",
    "    dataset.SetProjection(projection)\n",
    "    dataset.GetRasterBand(1).WriteArray(save_array)\n",
    "    dataset.FlushCache()\n",
    "    return dataset, dataset.GetRasterBand(1)  #If you need to return, remenber to return  also the dataset because the band don`t live without dataset.\n",
    "\n",
    "# create projection object without having an images\n",
    "gdf = gpd.read_file(shapefile, driver=\"ESRI Shapefile\")\n",
    "def create_projection_from_epsg(epsg):\n",
    "    \"\"\"\n",
    "    :type espg: int\n",
    "    \"\"\"\n",
    "    from hummingbirdtech.domain.image import Projection\n",
    "    sr = osr.SpatialReference()\n",
    "    sr.ImportFromEPSG(epsg)\n",
    "    return Projection(spatial_reference=sr)\n",
    "projection = create_projection_from_epsg(epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutlierDetecter(object):\n",
    "    \"\"\"\n",
    "    Class which contains different outlier detection / removal methods\n",
    "    \"\"\"\n",
    "    def __init__(self, image_array):\n",
    "        \"\"\"\n",
    "        Instantiating function that ensures the image is in the correct format / structure for\n",
    "        the outlier detection / removal techniques in the functions below to be carried out - this\n",
    "        refers to masking out the background and no data fill values. Note that this class takes a \n",
    "        2D array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if image has background / no data fill values and if so, mask them out.\n",
    "        if np.nanmin(image_array) <= 0:\n",
    "            mask = image_array <= 0\n",
    "            self.image_array = ma.array(image_array, mask=mask)\n",
    "        else:\n",
    "            self.image_array = image_array\n",
    "    # 1. z-score\n",
    "    def get_zscore(self, upper_threshold_value, lower_threshold_value):\n",
    "        \"\"\"\n",
    "        Function which returns a masked array of values within an upper and lower zscore threshold.\n",
    "        (Suggested threshold values: 2 & -2.)\n",
    "        \"\"\"\n",
    "        # calculate mean and std of image array (methods used depends on the type of array)\n",
    "        if type(self.image_array) == np.ma.core.MaskedArray:\n",
    "            mean = ma.mean(self.image_array)\n",
    "            std = ma.std(self.image_array)  \n",
    "        else:\n",
    "            mean = np.nanmean(self.image_array)\n",
    "            std = np.nanstd(self.image_array)       \n",
    "        # calculate z-score of each element in the image array\n",
    "        zscores = (self.image_array-mean) / std\n",
    "        # create mask of values within the thresholds given\n",
    "        mask = (zscores < lower_threshold_value) | (zscores > upper_threshold_value)\n",
    "        # return masked array\n",
    "        return ma.array(self.image_array, mask=mask)\n",
    "    # 2. modified z-score\n",
    "    def get_modified_zscore(self, upper_threshold_value, lower_threshold_value):\n",
    "        \"\"\"\n",
    "        Function which returns a masked array of values within an upper and lower modified zscore threshold.\n",
    "        (Suggested threshold values: 2 & -2)\n",
    "        \"\"\"\n",
    "        # calculate median and MAD (methods used depends on the type of array)\n",
    "        if type(self.image_array) == np.ma.core.MaskedArray: \n",
    "            median = ma.median(self.image_array)\n",
    "            median_absolute_deviation = ma.median(ma.abs(self.image_array-median)) \n",
    "        else:\n",
    "            median = np.nanmedian(self.image_array)\n",
    "            median_absolute_deviation = np.nanmedian(np.abs(self.image_array-median))\n",
    "        # return modified Z score of each element in the image array\n",
    "        modified_zscores = 0.6745 * (self.image_array-median) / median_absolute_deviation\n",
    "        # create mask of values within the thresholds given\n",
    "        mask = (modified_zscores < lower_threshold_value) | (modified_zscores > upper_threshold_value)\n",
    "        #return masked_array\n",
    "        return ma.array(self.image_array, mask=mask)\n",
    "    # 3. IQR\n",
    "    def get_iqr_outliers(self):\n",
    "        \"\"\"\n",
    "        Function which returns a masked array of values within an upper and lower IQR threshold\n",
    "        \"\"\"\n",
    "        # calculate first and third quartile(methods used depends on the type of array)\n",
    "        if type(self.image_array) == np.ma.core.MaskedArray:\n",
    "            q1, q3 = np.nanpercentile(self.image_array.filled(np.nan), (25,75))\n",
    "        else:\n",
    "            q1, q3 = np.nanpercentile(self.image_array, (25, 75))\n",
    "        # get interquartile range\n",
    "        interquartile_range = q3 - q1\n",
    "        # calculate upper and lower bounds\n",
    "        lower_bound = q1 - (interquartile_range*1.5)\n",
    "        upper_bound = q3 + (interquartile_range*1.5)\n",
    "        # create mask of values within the threshold given\n",
    "        mask = (self.image_array < lower_bound) | (self.image_array > upper_bound)\n",
    "        return ma.array(self.image_array, mask=mask)\n",
    "    # 4. sigma thresholding\n",
    "    def sigma_threshold(self, sigma_threshold):\n",
    "        \"\"\"\n",
    "        Function which returns a masked array of values within an upper and sigma threshold\n",
    "        (Suggested threshold sigma value: 2)\n",
    "        \"\"\"\n",
    "        # calculate mean\n",
    "        mean = np.nanmean(self.image_array)\n",
    "        # calculate std\n",
    "        sd = np.nanstd(self.image_array)\n",
    "        # set mask image according to specified sigma value\n",
    "        mask = (self.image_array < mean - sigma_threshold * sd) | (self.image_array > mean + sigma_threshold * sd)\n",
    "        return ma.array(self.image_array, mask=mask)\n",
    "\n",
    "# save pickle file\n",
    "import pickle\n",
    "class MacOSFile(object):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "pickle_dump(df, 'saved_pickle_file.pkl')\n",
    "\n",
    "# load pickle file\n",
    "with open('/Users/AlexKemp/Hummingbird/Classification/Pickle_Jar/polygon_pixel_vals.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Keyboard Shortcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# options - jupyter notebook\n",
    "cmd + shift + p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generic Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE STORE\n",
    "from hummingbirdtech.dic.container import Container\n",
    "image_store = Container().get('hummingbird.reflectance.image_store')\n",
    "survey_repository = Container().get('hummingbird.survey.repository')\n",
    "survey = survey_repository.find_one_by_identity('303')\n",
    "image = image_store.load(survey)\n",
    "red_band = image.get_band(survey.sensor.red.name) # primary method to load band\n",
    "red_band = image.get_band(survey.sensor.band('red').name) # if you need to get the band using a string\n",
    "band = InMemoryBand(name, data, geotransform, projection, no_data_value) # build band\n",
    "image = Image([band]) # build image\n",
    "\n",
    "# SK LEARN - instantiate class -> fit model to data -> transform (or predict) data with fitted model\n",
    "# e.g. \n",
    "scaler = MinMaxScaler()\n",
    "fit = scaler.fit(image_array)\n",
    "transform = fit.transform(image_array)\n",
    "\n",
    "# VRA GRIDDING\n",
    "Essentially there are a few steps:\n",
    "1) Create an `Image`, either just an ortho or classification map or GAI map etc\n",
    "2) Use field boundary to grid this into a list of `Grid` objects\n",
    "3) Extract average values and polygons from `Grid` objects and turn them into `VariableRateApplicationBoundary` objects\n",
    "4) Put `VariableRateApplicationBoundaryCollection` into `BaseApplicator` to normalise, clip by std etc... (edited)\n",
    "Most of this is being pushed into Domain:\n",
    "- `Grid` object lives in `domain`\n",
    "- `VariableRateApplicationBoundary` objects also live in domain\n",
    "- `BaseApplicator` (if you need it) currently lives in Nitrogen code base however is going to be moved in this sprint (edited)\n",
    "\n",
    "# start ssh agent and permanently add agent to it\n",
    "$ (ssh-agent)\n",
    "$ ssh-add\n",
    "$ ssh-add -K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
